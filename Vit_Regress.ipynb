{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f323998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 18:51:21.723475: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-03 18:51:21.814781: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-03 18:51:22.267724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/kannika/miniconda3/envs/vit-tf/lib/:/home/kannika/miniconda3/envs/vit-tf/lib/:/home/kannika/miniconda3/envs/vit-tf/lib/\n",
      "2023-03-03 18:51:22.267772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/kannika/miniconda3/envs/vit-tf/lib/:/home/kannika/miniconda3/envs/vit-tf/lib/:/home/kannika/miniconda3/envs/vit-tf/lib/\n",
      "2023-03-03 18:51:22.267777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/kannika/miniconda3/envs/vit-tf/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import glob, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import callbacks as callbacks_\n",
    "from tensorflow.keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b373199",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b90feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224 \n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "# EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d313a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19778, 9)\n",
      "(3857, 9)\n"
     ]
    }
   ],
   "source": [
    "DF = pd.read_csv('/home/kannika/codes_AI/Rheology2023/datasetMSDT_train_valid.csv')\n",
    "DF_TRAIN = DF[DF['subset']=='train'].reset_index(drop=True)\n",
    "print(DF_TRAIN.shape)\n",
    "DF_VAL = DF[DF['subset']=='valid'].reset_index(drop=True)\n",
    "print(DF_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9358bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      brightness_range=[0.5,1.5],\n",
    "      shear_range=0.4,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=False,\n",
    "      fill_mode='constant')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b772851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19778 validated image filenames.\n",
      "Found 3857 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "## DataSet\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe = DF_TRAIN,\n",
    "        directory = None,\n",
    "        x_col = 'pathimg',\n",
    "        y_col = 'MSDT',\n",
    "        target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        color_mode= 'rgb',\n",
    "        class_mode='raw')\n",
    "\n",
    "val_generator = valid_datagen.flow_from_dataframe(\n",
    "        dataframe = DF_VAL,\n",
    "        directory = None,\n",
    "        x_col = 'pathimg',\n",
    "        y_col = 'MSDT',\n",
    "        target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        color_mode= 'rgb',\n",
    "        class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "910652d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set TensorBoard \n",
    "from tensorflow.keras import callbacks\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "root_logdir = f'/media/SSD/rheology2023/VitModel/Regression/tensorflow/ExpTest/R1/Mylogs_tensor/'\n",
    "if not os.path.exists(root_logdir) :\n",
    "    os.makedirs(root_logdir)\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "    return os.path.join(root_logdir,run_id)\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = callbacks.TensorBoard(log_dir=run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3013224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 19:05:55.233270: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-03 19:05:55.666914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9517 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-L_32_imagenet21k+imagenet2012.npz\n",
      "1226658854/1226658854 [==============================] - 197s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kannika/miniconda3/envs/vit-tf/lib/python3.8/site-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 12, 12 to 7, 7\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### ViT model with the functional ###\n",
    "from vit_keras import vit, utils\n",
    "\n",
    "vit_model = vit.vit_l32(\n",
    "        image_size = IMAGE_SIZE,\n",
    "        pretrained = True,\n",
    "        include_top = False,\n",
    "        pretrained_top = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "948a3129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f2d185f5d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c806f7e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vit-l32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " embedding (Conv2D)          (None, 7, 7, 1024)        3146752   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 49, 1024)          0         \n",
      "                                                                 \n",
      " class_token (ClassToken)    (None, 50, 1024)          1024      \n",
      "                                                                 \n",
      " Transformer/posembed_input   (None, 50, 1024)         51200     \n",
      " (AddPositionEmbs)                                               \n",
      "                                                                 \n",
      " Transformer/encoderblock_0   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_1   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_2   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_3   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_4   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_5   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_6   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_7   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_8   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_9   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_10  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_11  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_12  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_13  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_14  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_15  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_16  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_17  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_18  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_19  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_20  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_21  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_22  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_23  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoder_norm (L  (None, 50, 1024)         2048      \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " ExtractToken (Lambda)       (None, 1024)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305,510,400\n",
      "Trainable params: 305,510,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vit_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3498ec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'ExtractToken')>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = vit_model.get_layer('ExtractToken').output\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db2c945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### add the tail layer ###  \n",
    "Flatten_layer1 = layers.Flatten()(x)\n",
    "BatchNormalization_layer1 = layers.BatchNormalization(name='BatchNormalization_1')(Flatten_layer1)\n",
    "Dense_layer1 = layers.Dense(64, activation='gelu',name='Dense_regress')(BatchNormalization_layer1)\n",
    "BatchNormalization_layer2 = layers.BatchNormalization(name='BatchNormalization_2')(Dense_layer1)\n",
    "Dense_layer2 = layers.Dense(1, activation='linear',name='linear_regress')(BatchNormalization_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35f61e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " embedding (Conv2D)          (None, 7, 7, 1024)        3146752   \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 49, 1024)          0         \n",
      "                                                                 \n",
      " class_token (ClassToken)    (None, 50, 1024)          1024      \n",
      "                                                                 \n",
      " Transformer/posembed_input   (None, 50, 1024)         51200     \n",
      " (AddPositionEmbs)                                               \n",
      "                                                                 \n",
      " Transformer/encoderblock_0   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_1   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_2   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_3   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_4   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_5   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_6   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_7   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_8   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_9   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_10  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_11  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_12  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_13  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_14  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_15  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_16  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_17  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_18  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_19  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_20  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_21  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_22  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_23  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoder_norm (L  (None, 50, 1024)         2048      \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " ExtractToken (Lambda)       (None, 1024)              0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " BatchNormalization_1 (Batch  (None, 1024)             4096      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " Dense_regress (Dense)       (None, 64)                65600     \n",
      "                                                                 \n",
      " BatchNormalization_2 (Batch  (None, 64)               256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " linear_regress (Dense)      (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305,580,417\n",
      "Trainable params: 305,578,241\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Model(inputs= vit_model.input, outputs=[Dense_layer2]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3262909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable layers before freezing the conv base: 398\n",
      "This is the number of trainable layers after freezing the conv base: 8\n",
      "--------------------------------------------------------------------------------\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " embedding (Conv2D)          (None, 7, 7, 1024)        3146752   \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 49, 1024)          0         \n",
      "                                                                 \n",
      " class_token (ClassToken)    (None, 50, 1024)          1024      \n",
      "                                                                 \n",
      " Transformer/posembed_input   (None, 50, 1024)         51200     \n",
      " (AddPositionEmbs)                                               \n",
      "                                                                 \n",
      " Transformer/encoderblock_0   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_1   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_2   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_3   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_4   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_5   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_6   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_7   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_8   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_9   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_10  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_11  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_12  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_13  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_14  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_15  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_16  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_17  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_18  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_19  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_20  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_21  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_22  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_23  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoder_norm (L  (None, 50, 1024)         2048      \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " ExtractToken (Lambda)       (None, 1024)              0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " BatchNormalization_1 (Batch  (None, 1024)             4096      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " Dense_regress (Dense)       (None, 64)                65600     \n",
      "                                                                 \n",
      " BatchNormalization_2 (Batch  (None, 64)               256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " linear_regress (Dense)      (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305,580,417\n",
      "Trainable params: 67,841\n",
      "Non-trainable params: 305,512,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Freeze\n",
    "print('This is the number of trainable layers '\n",
    "          'before freezing the conv base:', len(model.trainable_weights))\n",
    "for layer in vit_model.layers:\n",
    "    layer.trainable = False\n",
    "print('This is the number of trainable layers '\n",
    "          'after freezing the conv base:', len(model.trainable_weights))\n",
    "print('-'*80)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e665e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de7859d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tfa.optimizers.RectifiedAdam(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60bf3446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer = Adam(2e-6, decay=1e-6), \n",
    "              loss = 'mse', \n",
    "              metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "027e097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = val_generator.n // val_generator.batch_size\n",
    "\n",
    "root_base = '/media/SSD/rheology2023/VitModel/Regression/tensorflow/Exptest'\n",
    "if not os.path.exists(root_base) :\n",
    "    os.makedirs(root_base)\n",
    "os.chdir(root_base)\n",
    "\n",
    "## reduce_lr, checkpointer ต้องเปลี่ยนใหม่\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss',  ##เปลี่ยนชื่อเป็น Validation_loss \n",
    "                                                 factor = 0.2,\n",
    "                                                 patience = 2,\n",
    "                                                 verbose = 1,\n",
    "                                                 min_delta = 1e-5,\n",
    "                                                 min_lr = 1e-6,\n",
    "                                                 mode = 'max')\n",
    "\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath = './modelRegress_ViT_l32_Rheology.hdf5',\n",
    "                                                  monitor = 'val_loss', \n",
    "                                                  verbose = 1, \n",
    "                                                  save_best_only = True,\n",
    "                                                  save_weights_only = True,\n",
    "                                                  mode = 'max')\n",
    "\n",
    "callbacks = [reduce_lr, checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64009bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 19:33:11.303448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-03 19:33:12.144561: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-03 19:33:12.145524: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-03 19:33:12.145550: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:85] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-03 19:33:12.146396: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-03 19:33:12.146476: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236/1236 [==============================] - ETA: 0s - loss: 118.1770 - mse: 118.1770\n",
      "Epoch 1: val_loss improved from -inf to 134.56284, saving model to ./modelRegress_ViT_l32_Rheology.hdf5\n",
      "1236/1236 [==============================] - 286s 218ms/step - loss: 118.1770 - mse: 118.1770 - val_loss: 134.5628 - val_mse: 134.5628 - lr: 2.0000e-06\n",
      "Epoch 2/3\n",
      "1236/1236 [==============================] - ETA: 0s - loss: 115.3145 - mse: 115.3145\n",
      "Epoch 2: val_loss did not improve from 134.56284\n",
      "1236/1236 [==============================] - 263s 213ms/step - loss: 115.3145 - mse: 115.3145 - val_loss: 113.5808 - val_mse: 113.5808 - lr: 2.0000e-06\n",
      "Epoch 3/3\n",
      "1236/1236 [==============================] - ETA: 0s - loss: 112.6565 - mse: 112.6565\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 3: val_loss did not improve from 134.56284\n",
      "1236/1236 [==============================] - 264s 214ms/step - loss: 112.6565 - mse: 112.6565 - val_loss: 101.6923 - val_mse: 101.6923 - lr: 2.0000e-06\n"
     ]
    }
   ],
   "source": [
    "root_logdir = f'{root_base}/run_log'  #เปลี่ยน R1_1 เปลี่ยนตาม fold\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "    return os.path.join(root_logdir,run_id)\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = callbacks_.TensorBoard(log_dir = run_logdir)\n",
    "\n",
    "\n",
    "def avoid_error(gen):\n",
    "    while True:\n",
    "        try:\n",
    "            data, labels = next(gen)\n",
    "            yield data, labels\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "model.fit(x = avoid_error(train_generator),\n",
    "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "          validation_data = val_generator,\n",
    "          validation_steps = STEP_SIZE_VALID,\n",
    "          epochs = EPOCHS,\n",
    "          callbacks = callbacks)\n",
    "\n",
    "model.save('./models/modelRegress_ViT_l32_Rheology_R1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d225b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28150342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b684bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b13af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a14d414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vit-l32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " embedding (Conv2D)          (None, 7, 7, 1024)        3146752   \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 49, 1024)          0         \n",
      "                                                                 \n",
      " class_token (ClassToken)    (None, 50, 1024)          1024      \n",
      "                                                                 \n",
      " Transformer/posembed_input   (None, 50, 1024)         51200     \n",
      " (AddPositionEmbs)                                               \n",
      "                                                                 \n",
      " Transformer/encoderblock_0   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_1   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_2   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_3   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_4   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_5   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_6   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_7   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_8   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_9   ((None, 50, 1024),       12596224  \n",
      " (TransformerBlock)           (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_10  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_11  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_12  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_13  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_14  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_15  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_16  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_17  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_18  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_19  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_20  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_21  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_22  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_23  ((None, 50, 1024),       12596224  \n",
      "  (TransformerBlock)          (None, 16, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoder_norm (L  (None, 50, 1024)         2048      \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " ExtractToken (Lambda)       (None, 1024)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305,510,400\n",
      "Trainable params: 305,510,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### ViT model with the functional ###\n",
    "from vit_keras import vit, utils\n",
    "\n",
    "vit_model = vit.vit_l32(\n",
    "        image_size = IMAGE_SIZE,\n",
    "        activation = 'softmax',\n",
    "        pretrained = True,\n",
    "        include_top = False,\n",
    "        pretrained_top = False,\n",
    "        classes = 14)\n",
    "vit_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f8d7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f9adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f64fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305ea87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit-tf",
   "language": "python",
   "name": "vit-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
